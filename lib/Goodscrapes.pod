=pod

=encoding utf8

=head1 NAME

Goodscrapes - Simple Goodreads.com scraping helpers


=head1 VERSION

=over

=item * Updated: 2018-07-06

=item * Since: 2014-11-05

=back

=head1 COMPARED TO THE OFFICIAL API

=over

=item * focuses on analysing, not updating info on GR

=item * less limited, e.g., reading shelves and reviews of other members

=item * official API is slow too; API users are even second-class citizen

=item * theoretically this library is more likely to break, 
        but Goodreads progresses very very slowly: nothing
        actually broke since 2014 (I started this);
        actually their API seems to change more often than
        their web pages; they can and do disable API functions 
        without being noticed by the majority, but they cannot
        easily disable important webpages that we use too

=back


=head1 LIMITATIONS

=over

=item * slow: version with concurrent AnyEvent::HTTP requests was marginally 
        faster, so I sticked with simpler code; doesn't actually matter
        due to Amazon's and Goodreads' request throttling. You can only
        speed things up significantly with a pool of work-sharing computers 
        and unique IP addresses...

=item * just text pattern matching, no ECMAScript execution and DOM parsing
        (so far sufficient and faster)

=back


=head1 AUTHOR

https://github.com/andre-st/


=head1 DATA STRUCTURES

=head2 Note

=over

=item * never cast 'id' to int or use %d format string, despite digits only, 
        compare as strings

=item * don't expect all attributes set (C<undef>), this depends on context

=back


=head2 %book

=over

=item * id          => C<string>

=item * title       => C<string>

=item * isbn        => C<string>

=item * num_ratings => C<int>

=item * user_rating => C<int>

=item * url         => C<string>

=item * img_url     => C<string>

=item * author      => C<L<%user|"%user">>

=back


=head2 %user

=over

=item * id         => C<string>

=item * name       => C<string>

=item * age        => C<int> (not supported yet)

=item * is_friend  => C<bool>

=item * is_author  => C<bool>

=item * is_female  => C<bool> (not supported yet)

=item * is_private => C<bool> (not supported yet)

=item * url        => C<string> URL to the user's profile page

=item * works_url  => C<string> URL to the author's distinct works (is_author == 1)

=item * img_url    => C<string>

=back


=head2 %review

=over

=item * id          => C<string>

=item * user        => C<L<%user|"%user">>

=item * book_id     => C<string>

=item * rating      => C<int> 
                       with 0 meaning no rating, "added" or "marked it as abandoned" 
                       or something similar

=item * rating_str  => C<string> 
                       represention of rating, e.g., 3/5 as S<"[***  ]"> or S<"[TTT  ]"> 
                       if there's additional text

=item * text        => C<string>

=item * date        => C<Time::Piece>

=item * review_url  => C<string>

=back

=head1 PUBLIC SUBROUTINES



=head2 C<string> require_good_userid( I<$user_id_to_verify> )

=over

=item * returns a sanitized, valid Goodreads user id or kills 
        the current process with an error message

=back

=head2 C<string> require_good_shelfname( I<$name_to_verify> )

=over

=item * returns the given shelf name if valid 

=item * returns a shelf which includes all books if no name given

=item * kills the current process with an error message if name is malformed

=back

=head2 C<bool> is_bad_profile( I<$user_or_author_id> )

=over

=item * blacklist with users and authors who dirty and slow down any analysis

=item * "NOT A BOOK" authors (3.000+ books)

=item * known non-orgs with 100.000+ books (probably bots or analytics accounts)

=back

=head2 C<void> set_good_cookie( I<$cookie_content_str> )

=over

=item * some Goodreads.com pages are only accessible by authenticated members

=item * copy-paste cookie from Chrome's DevTools network-view

=back

=head2 C<void> set_good_cookie_file( I<$path_to_cookie_file = '.cookie'> )

=head2 C<bool> test_good_cookie()

=over

=item * not supported at the moment

=back

=head2 C<void> set_good_cache( I<$maximum_age_in_words> )

=over

=item * scraping Goodreads.com is a very slow process

=item * scraped documents can be cached if you don't need them "fresh"

=item * e.g., during development time

=item * e.g., during long running sessions (cheap recovery on crash, power blackout or pauses)

=item * if process is to repeat with different parameters

=item * pass something like C<"60 minutes">, C<"6 hours">, C<"6 days">

=back

=head2 C<(L<%book|"%book">,...)> query_good_books( I<$user_id, $shelf_name> )

=head2 C<(L<%book|"%book">,...)> query_good_author_books( I<$author_id> )

=head2 C<(L<%review|"%review">,...)> query_good_reviews( I<$book_id, $since_time_piece = undef> )

=over

=item * access seems less throttled / faster than querying books

=back

=head2 C<(id =E<gt> L<%user|"%user">,...)> query_good_followees( I<$user_id> )

=over

=item * Precondition: set_good_cookie()

=item * returns friends AND followees

=back

=head2 C<(L<%user|"%user">,...)> query_similar_authors( I<$author_id> )
	
=head2 C<string> amz_book_html( I<L<%book|"%book">> )

=over

=item * HTML body of an Amazon article page

=back

=head1 PRIVATE SUBROUTINES



=head2 C<string> _amz_url( I<L<%book|"%book">> )

=over

=item * Requires at least {isbn=>string}

=back

=head2 C<string> _shelf_url( I<$user_id, $shelf_name, $page_number = 1> )

=over

=item * URL for a page with a list of books (not all books)

=item * "&per_page=100" has no effect (GR actually loads 5x 20 books via JavaScript)

=item * "&print=true" not included, any advantages?

=item * "&view=table" puts I<all> book data in code, although invisible (display=none)

=item * "&sort=rating" is important for `friendrated.pl` with its book limit:
        Some users read 9000+ books and scraping would take forever. 
        We sort lower-rated books to the end and just scrape the first pages:
        Even those with 9000+ books haven't top-rated more than 2700 books.

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> _followees_url( I<$user_id, $page_number = 1> )

=over

=item * URL for a page with a list of the people $user is following

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> _friends_url( I<$user_id, $page_number = 1> )

=over

=item * URL for a page with a list of people befriended to C<$user_id>

=item * "&sort=date_added" (as opposed to 'last online') avoids 
        moving targets while reading page by page

=item * "&skip_mutual_friends=false" because we're not doing
        this just for me

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> _book_url( I<$book_id> )

=head2 C<string> _user_url( I<$user_id, $is_author = 0> )

=head2 C<string> _reviews_url( I<$book_id, $can_sort_newest, $page_number = 1> )

=over

=item * "&sort=newest" reduces the number of reviews for some reason (also observable 
        on the Goodreads website), so only use if really needed (&sort=default)

=item * the maximum of retrievable reviews is 300 (state 2018-06-22)

=back

=head2 C<string> _review_url( I<$review_id> )

=head2 C<string> _author_books_url( I<$user_id, $page_number = 1> )

=head2 C<string> _author_followings_url( I<$author_id, $page_number = 1> )

=head2 C<string> _similar_authors_url( I<$author_id> )

=over

=item * page number > N just returns same page, so no easy stop criteria;
        not sure, if there's more than page, though

=back

=head2 C<(L<%book|"%book">,...)> _extract_books( I<$shelf_tableview_html_str> )

=head2 C<(L<%book|"%book">,...)> _extract_author_books( I<$html_str> )

=head2 C<(L<%user|"%user">,...)> _extract_followees( I<$following_page_html_str> )

=head2 C<(L<%user|"%user">,...)> _extract_friends( I<$friends_page_html_str> )

=head2 C<(L<%review|"%review">,...)> _extract_reviews( I<$since_time_piece, $reviews_xhr_html_str> )

=head2 C<(L<%user|"%user">,...)> _extract_similar_authors( I<$author_id_to_skip, $similar_page_html_str> )

=head2 C<bool> _check_page( I<$url, $html> )

=over

=item * warns if sign-in page (https://www.goodreads.com/user/sign_in) or in-page message

=item * warns if "page unavailable, Goodreads request took too long"

=item * warns if "page not found" (TODO)

=item * dies if page unavailable: "An unexpected error occurred. 
        We will investigate this problem as soon as possible â€” please 
        check back soon!"

=item * dies if over capacity (TODO UNTESTED):
        "<?>Goodreads is over capacity.</?> 
        <?>You can never have too many books, but Goodreads can sometimes
        have too many visitors. Don't worry! We are working to increase 
        our capacity.</?>
        <?>Please reload the page to try again.</?>
        <a ...>get the latest on Twitter</a>"
        https://pbs.twimg.com/media/DejvR6dUwAActHc.jpg
        https://pbs.twimg.com/media/CwMBEJAUIAA2bln.jpg
        https://pbs.twimg.com/media/CFOw6YGWgAA1H9G.png  (with title)

=item * dies if maintenance mode (TODO UNTESTED):
        "<?>Goodreads is down for maintenance.</?>
        <?>We expect to be back within minutes. Please try again soon!<?>
        <a ...>Get the latest on Twitter</a>"
        https://pbs.twimg.com/media/DgKMR6qXUAAIBMm.jpg
        https://i.redditmedia.com/-Fv-2QQx2DeXRzFBRKmTof7pwP0ZddmEzpRnQU1p9YI.png

=item * dies if website temporarily unavailable (TODO UNTESTED):
        Our website is currently unavailable while we make some improvements
        to our service. We'll be open for business again soon,
        please come back shortly to try again. <?>
        Thank you for your patience. (No Alice error)
        https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/hostedimages/1404319071i/10224522.png

=back

=head2 C<string> _html( I<$url> )

=over

=item * HTML body of a web document

=item * might stop process on severe problems

=back

