=pod

=encoding utf8

=head1 NAME

Goodscrapes - Simple Goodreads.com scraping helpers


=head1 VERSION

=over

=item * Updated: 2018-05-15

=item * Since: 2014-11-05

=back

=head1 KNOWN LIMITATIONS AND BUGS

=over

=item * slow: version with concurrent AnyEvent::HTTP requests was marginally 
        faster, so I sticked with simpler code; but might be up to my system

=back


=head1 AUTHOR

https://github.com/andre-st/


=head1 DATA STRUCTURES

=head2 Note

=over

=item * never cast 'id' to int or use %d format string, despite digits only

=back


=head2 %book

=over

=item * id          => C<string>

=item * title       => C<string>

=item * isbn        => C<string>

=item * num_ratings => C<int>

=item * user_rating => C<int>

=item * url         => C<string>

=item * img_url     => C<string>

=back


=head2 %user

=over

=item * id          => C<string>

=item * name        => C<string>

=item * age         => C<int>

=item * is_friend   => C<bool>

=item * is_author   => C<bool>

=item * is_female   => C<bool>

=item * profile_url => C<string>

=item * img_url     => C<string>

=back


=head2 %review

=over

=item * id         => C<string>

=item * user       => C<L<%user|"%user">>

=item * book_id    => C<string>

=item * rating     => C<int>

=item * rating_str => C<string> represention of rating, e.g., 3 as "***--"

=item * text       => C<string>

=item * date       => C<Time::Piece>

=item * review_url => C<string>

=back

=head1 SUBROUTINES



=head2 C<void> set_good_cookie( I<$cookie_content_str> )

=over

=item * some Goodreads.com pages are only accessible by authenticated members

=item * copy-paste cookie from Chrome's DevTools network-view

=back

=head2 C<void> set_good_cookie_file( I<$path_to_cookie_file> )

=head2 C<void> set_good_cache( I<$maximum_age_in_words> )

=over

=item * scraping Goodreads.com is a very slow process

=item * scraped documents can be cached if you don't need them "fresh"

=item * e.g., during development time

=item * e.g., during long running sessions (cheap recovery on crash or pause)

=item * pass something like C<"60 minutes">, C<"6 hours">, C<"6 days">

=back

=head2 C<string> good_shelf_url( I<$user_id, $shelf_name, $page_number> )

=head3 Notes on the URL

=over

=item * page with a list of books (not all books)

=item * "&per_page=100" has no effect (GR actually loads 5x 20 books via JavaScript)

=item * "&view=table" puts I<all> book data in code, although invisible (display=none)

=item * "&sort=rating" is important for `friendrated.pl` with its book limit:
        Some users read 9000+ books and scraping would take forever. 
        We sort lower-rated books to the end and just scrape the first pages:
        Even those with 9000+ books haven't top-rated more than 2700 books.

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> good_following_url( I<$user_id, $page_number> )

=head3 Notes on the URL

=over

=item * page with a list of the people $user is following

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> good_friends_url( I<$user_id, $page_number> )

=head3 Notes on the URL

=over

=item * page with a list of people befriended to C<$user_id>

=item * "&sort=date_added" (as opposed to 'last online') avoids 
        moving targets while reading page by page

=item * "&skip_mutual_friends=false" because we're not doing
        this just for me

=item * B<Warning:> changes to the URL structure will bust the file-cache

=back

=head2 C<string> good_book_url( I<L<%book|"%book">> )

=over

=item * Requires at least {id=>string}

=back

=head2 C<string> good_user_url( I<$user_id, $is_author = 0> )

=head2 C<string> good_reviews_url( I<$book_id> )

=head2 C<string> good_review_url( I<$review_id> )

=head2 C<string> amz_url( I<L<%book|"%book">> )

=over

=item * Requires at least {isbn=>string}

=back

=head2 C<string> amz_book_html( I<L<%book|"%book">> )

=over

=item * HTML body of an Amazon article page

=back

=head2 C<(L<%book|"%book">,...)> _extract_books( I<$shelf_tableview_html_str> )

=head2 C<(L<%user|"%user">,...)> _extract_following( I<$following_page_html_str> )

=head2 C<(L<%user|"%user">,...)> _extract_friends( I<$friends_page_html_str> )

=head2 C<(L<%review|"%review">,...)> _extract_reviews( I<$reviews_xhr_html_str> )

=head2 C<string> html( I<$url> )

=over

=item * HTML body of a web document

=back

=head2 C<(L<%book|"%book">,...)> query_good_books( I<$user_id, $shelf_name, $max_books = 2700> )

=head2 C<(L<%review|"%review">,...)> query_good_reviews( I<$book_id, $since_time_piece> )

=over

=item * latest reviews first

=back

=head2 {id=>L<%user|"%user">} query_acquaint( I<$user_id> )

=head3 Preconditions

=over

=item * set_good_cookie()

=back

